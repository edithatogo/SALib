# -*- coding: utf-8 -*-
"""
This module implements a correlation-aware Sobol sensitivity analysis method,
calculating 'full' first-order and total-order indices.
"""
import numpy as np
from scipy.stats import norm
from multiprocess import Pool # For parallel bootstrapping
from SALib.util import ResultDict # For structuring results
import warnings

# Define the worker function for bootstrapping (must be top-level for pickling)
def _bootstrap_sobol_correlated_worker(args):
    """
    Worker function for parallel bootstrapping of correlated Sobol' indices.
    Recalculates S1_full and ST_full for a single bootstrap sample of Y values.
    """
    (   Y_A_boot, Y_B_boot, Y_C_i_all_boot, Y_D_i_all_boot,
        D_vars, N_base, V_Y_total_variance_boot # Pass total variance of this bootstrap sample
    ) = args

    s1_full_boot = np.empty(D_vars)
    st_full_boot = np.empty(D_vars)

    # Calculate S1_full for this bootstrap sample
    for i in range(D_vars):
        Y_Ci_boot = Y_C_i_all_boot[:, i] # Y_C_i for this bootstrap sample
        # Numerator: Cov(Y_A_boot, Y_Ci_boot)
        s1_numerator = np.mean(Y_A_boot * Y_Ci_boot) - (np.mean(Y_A_boot) * np.mean(Y_Ci_boot))
        s1_full_boot[i] = s1_numerator / V_Y_total_variance_boot if V_Y_total_variance_boot != 0 else 0.0


    # Calculate ST_full for this bootstrap sample
    for i in range(D_vars):
        Y_Di_boot = Y_D_i_all_boot[:, i] # Y_D_i for this bootstrap sample
        st_full_boot[i] = (0.5 * np.mean((Y_A_boot - Y_Di_boot)**2)) / V_Y_total_variance_boot if V_Y_total_variance_boot != 0 else 0.0

    return s1_full_boot, st_full_boot


def analyze(problem: dict, Y: np.ndarray, calc_second_order: bool = True,
            num_resamples: int = 100, conf_level: float = 0.95,
            print_to_console: bool = False, seed: int = None,
            parallel: bool = False, n_processors: int = None) -> ResultDict:
    """
    Performs a correlation-aware Sobol sensitivity analysis on model outputs.

    This function estimates "full" first-order (S1_full) and total-order (ST_full)
    sensitivity indices. These indices account for correlations between input
    parameters and their interpretation differs from standard Sobol' indices
    (which assume input independence).

    The implemented estimators are:
    - For S1_full_i:
      :math:`S1\_full_i = ( \\frac{1}{N} \\sum_{k=1}^{N} Y_A^{(k)} Y_{C_i}^{(k)} - E[Y_A] E[Y_{C_i}] ) / V(Y)`
      This estimates :math:`Cov(Y_A, Y_{C_i}) / V(Y)`, where :math:`Y_A = f(X_A)`
      and :math:`Y_{C_i} = f(X_{A,i}, X_{B,\\sim i})`.
    - For ST_full_i:
      :math:`ST\_full_i = ( \\frac{1}{2N} \\sum_{k=1}^{N} (Y_A^{(k)} - Y_{D_i}^{(k)})^2 ) / V(Y)`
      This estimates :math:`(0.5 \\times E[(Y_A - Y_{D_i})^2]) / V(Y)`, where
      :math:`Y_{D_i} = f(X_{A,\\sim i}, X_{B,i})`.

    These estimators are consistent with approaches for estimating "full"
    sensitivity indices in the presence of correlated inputs, such as those
    discussed in literature (e.g., Janon et al., 2013, Comm. App. Ind. Math.;
    Mara & Tarantola, 2012, RESS; Kucherenko et al., 2009, CPC). Users should
    consult these references for a detailed theoretical background.
    This implementation should be considered **experimental**.

    It expects model outputs `Y` generated from samples produced by
    `SALib.sample.sobol_correlated.sample()`.

    Parameters
    ----------
    problem : dict
        The problem definition, including:
        - `num_vars` (int): Number of input variables.
        - `names` (list): List of variable names.
        - `corr_matrix` (np.ndarray): The correlation matrix used for sampling.
    Y : np.ndarray
        A NumPy array containing the model outputs. Must correspond to samples
        generated by `sample_sobol_correlated`. Expected length is N * (2 + 2*D).
    calc_second_order : bool, optional
        If True, this flag is noted, but current implementation only provides
        S1_full and ST_full. Second-order "full" effects are not yet implemented.
        Default is True.
    num_resamples : int, optional
        Number of bootstrap resamples for confidence interval estimation (default 100).
    conf_level : float, optional
        Confidence level for bootstrap intervals (default 0.95).
    print_to_console : bool, optional
        If True, prints results to console (default False).
    seed : int, optional
        Seed for random number generation (for bootstrapping).
    parallel : bool, optional
        If True, parallelizes bootstrap computations (default False).
    n_processors : int, optional
        Number of processors for parallel bootstrap (default None).

    Returns
    -------
    ResultDict
        A dictionary containing the sensitivity indices:
        - `S1_full` (np.array): Full first-order indices.
        - `S1_full_conf` (np.array): Confidence intervals for S1_full.
        - `ST_full` (np.array): Full total-order indices.
        - `ST_full_conf` (np.array): Confidence intervals for ST_full.
    """
    if seed is not None:
        np.random.seed(seed)

    D = problem['num_vars']

    if problem.get('corr_matrix') is None:
        # This should ideally be caught by sampler, but good to double check
        raise ValueError("`analyze_sobol_correlated` requires a `corr_matrix` in the problem definition.")

    if problem.get('groups') is not None:
        warnings.warn("Warning: `analyze_sobol_correlated` received a problem with 'groups' defined. "
                      "This method is not designed or validated for use with grouped sampling "
                      "in combination with its correlation-specific estimators. "
                      "Results may be unreliable.", UserWarning)

    # Infer N_base from Y and D
    # Total samples = N_base * (2 + 2*D)
    expected_block_size = 2 + 2 * D
    if Y.size % expected_block_size != 0:
        raise ValueError(f"Incorrect number of samples in Y. Expected a multiple of (2 + 2*D) = {expected_block_size}, "
                         f"but got Y.size = {Y.size}")
    N_base = Y.size // expected_block_size

    if N_base == 0:
        raise ValueError("Not enough samples in Y to perform analysis.")

    # Separate Y into Y_A, Y_B, Y_Ci_all, Y_Di_all
    Y_A = Y[0:N_base]
    Y_B = Y[N_base : 2 * N_base]

    Y_C_matrices_flat = Y[2 * N_base : N_base * (2 + D)]
    Y_D_matrices_flat = Y[N_base * (2 + D) : N_base * (2 + 2 * D)]

    # Reshape Y_C_i and Y_D_i into (N_base, D) arrays
    # Column j of Y_C_i_all corresponds to Y_Cj (output from X_Cj)
    Y_C_i_all = np.reshape(Y_C_matrices_flat, (N_base, D), order='F') # Fortran order for column major fill
    Y_D_i_all = np.reshape(Y_D_matrices_flat, (N_base, D), order='F')


    # Calculate Total Variance V_Y
    # Using Y_A and Y_B for variance calculation is a common choice.
    # Or use just Y_A. Let's use Y_A and Y_B.
    V_Y = np.var(np.concatenate((Y_A, Y_B)), ddof=1)
    if V_Y == 0: # Handle constant output case
        warnings.warn("Total variance of model output is zero. All sensitivity indices will be zero.", UserWarning)
        # Return zeros or NaNs
        S1_full = np.zeros(D)
        ST_full = np.zeros(D)
        S1_full_conf = np.full(D, np.nan)
        ST_full_conf = np.full(D, np.nan)

        Si = ResultDict([('S1_full', S1_full), ('S1_full_conf', S1_full_conf),
                         ('ST_full', ST_full), ('ST_full_conf', ST_full_conf)])
        Si['names'] = problem['names']
        if print_to_console: print(Si)
        return Si


    # Calculate Full First-Order Indices (S1_full)
    S1_full = np.empty(D)
    for i in range(D):
        Y_Ci = Y_C_i_all[:, i]
        # Numerator: Cov(Y_A, Y_Ci)
        s1_numerator = np.mean(Y_A * Y_Ci) - (np.mean(Y_A) * np.mean(Y_Ci))
        S1_full[i] = s1_numerator / V_Y

    # Calculate Full Total-Order Indices (ST_full)
    ST_full = np.empty(D)
    for i in range(D):
        Y_Di = Y_D_i_all[:, i]
        ST_full[i] = (0.5 * np.mean((Y_A - Y_Di)**2)) / V_Y

    # Confidence Intervals via Bootstrapping
    S1_full_conf_values = np.full(D, np.nan)
    ST_full_conf_values = np.full(D, np.nan)

    if num_resamples > 0:
        if parallel:
            # Prepare tasks for parallel execution
            # Each task needs bootstrapped Y_A, Y_B, Y_C_i_all, Y_D_i_all and the total variance of that bootstrap sample

            bootstrap_tasks = []
            rng_indices = np.random.randint(0, N_base, size=(num_resamples, N_base))

            for k in range(num_resamples):
                sample_indices = rng_indices[k, :]
                Y_A_boot = Y_A[sample_indices]
                Y_B_boot = Y_B[sample_indices]
                Y_C_i_all_boot = Y_C_i_all[sample_indices, :]
                Y_D_i_all_boot = Y_D_i_all[sample_indices, :]

                V_Y_boot = np.var(np.concatenate((Y_A_boot, Y_B_boot)), ddof=1)
                if V_Y_boot == 0: V_Y_boot = 1e-12 # Avoid division by zero in worker if output is constant for a bootstrap sample

                bootstrap_tasks.append((Y_A_boot, Y_B_boot, Y_C_i_all_boot, Y_D_i_all_boot, D, N_base, V_Y_boot))

            pool_processors = n_processors
            with Pool(processes=pool_processors) as pool:
                bootstrap_results = pool.map(_bootstrap_sobol_correlated_worker, bootstrap_tasks)

            # bootstrap_results is a list of tuples [(s1_full_resample1, st_full_resample1), ...]
            s1_full_resamples = np.array([res[0] for res in bootstrap_results]) # Shape (num_resamples, D)
            st_full_resamples = np.array([res[1] for res in bootstrap_results]) # Shape (num_resamples, D)

        else: # Serial bootstrapping
            s1_full_resamples = np.empty((num_resamples, D))
            st_full_resamples = np.empty((num_resamples, D))

            for k in range(num_resamples):
                sample_indices = np.random.randint(0, N_base, size=N_base)
                Y_A_boot = Y_A[sample_indices]
                Y_B_boot = Y_B[sample_indices]
                Y_C_i_all_boot = Y_C_i_all[sample_indices, :]
                Y_D_i_all_boot = Y_D_i_all[sample_indices, :]

                V_Y_boot = np.var(np.concatenate((Y_A_boot, Y_B_boot)), ddof=1)
                if V_Y_boot == 0: V_Y_boot = 1e-12 # Avoid division by zero if output is constant for a bootstrap sample

                args_for_worker = (Y_A_boot, Y_B_boot, Y_C_i_all_boot, Y_D_i_all_boot, D, N_base, V_Y_boot)
                s1_boot_k, st_boot_k = _bootstrap_sobol_correlated_worker(args_for_worker)
                s1_full_resamples[k, :] = s1_boot_k
                st_full_resamples[k, :] = st_boot_k

        # Calculate confidence intervals from bootstrap resamples
        z_norm = norm.ppf(0.5 + conf_level / 2.0)
        S1_full_conf_values = z_norm * np.std(s1_full_resamples, axis=0, ddof=1)
        ST_full_conf_values = z_norm * np.std(st_full_resamples, axis=0, ddof=1)

    # Store results
    Si = ResultDict([
        ('S1_full', S1_full),
        ('S1_full_conf', S1_full_conf_values),
        ('ST_full', ST_full),
        ('ST_full_conf', ST_full_conf_values)
    ])
    Si['names'] = problem['names'] # Store parameter names

    if print_to_console:
        # Basic print, ProblemSpec.to_df() might need adaptation for these new keys
        print(Si)

    return Si
